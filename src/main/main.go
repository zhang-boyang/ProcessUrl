package main

import (
	"bufio"
	"encoding/json"
	"heapsort"
	"io"
	"os"
	"pucommon"
	"sync"
)

//BASEDIR project data base dir
const BASEDIR = "../../data/"

//MAPPHASE map phase generates prefix file
const MAPPHASE = "map_task"

//REDUCEPHASE reduce phase generates prefix file
const REDUCEPHASE = "reduce_task"

//mapF recieve ch from taskCh, write into file separately by hash
func mapF(taskNo int, taskCh chan string, wg *sync.WaitGroup) {
	wg.Add(1)
	defer wg.Done()
	fileName := pucommon.MergeFileName(BASEDIR, MAPPHASE, taskNo)
	outfile, err := os.Create(fileName)
	if err != nil {
		panic("task error")
	}
	defer outfile.Close()
	for url := range taskCh {
		pucommon.PULOG(taskNo, url)
		outfile.WriteString(url + "\n")
	}
}

/*
	reduceF reduce every file generated by mapF, count the every singel url number
	and write down into file
*/
func reduceF(taskNo int, hp *heapsort.Heap, outputf *os.File) {
	mapFileName := pucommon.MergeFileName(BASEDIR, MAPPHASE, taskNo)
	infile, merr := os.Open(mapFileName)
	if merr != nil {
		panic("open file fail")
	}
	defer os.Remove(mapFileName)
	defer infile.Close()
	mapCnt := make(map[string]uint64)
	br := bufio.NewReader(infile)
	for {
		line, _, err := br.ReadLine()
		if err == io.EOF {
			break
		} else if err != nil {
			panic("read in reduce mapfile fail")
		}
		strKey := string(line)
		if _, ok := mapCnt[strKey]; ok {
			mapCnt[strKey]++
		} else {
			mapCnt[strKey] = 1
		}
	}
	pucommon.PULOG(mapCnt)
	ecjson := json.NewEncoder(outputf)
	for k, v := range mapCnt {
		kv := pucommon.KeyValue{
			Key:   k,
			Value: v,
		}
		hp.InsertHeap(&kv)
		ecjson.Encode(&kv)
	}
}

//write topN counted into file
func topNF(hp *heapsort.Heap) {
	topnfile, terr := os.Create(BASEDIR + "topn.txt")
	if terr != nil {
		panic("create topn file fail")
	}
	defer topnfile.Close()
	ecjson := json.NewEncoder(topnfile)
	for _, v := range hp.HeapSlice {
		err := ecjson.Encode(&v)
		if err != nil {
			panic("head slice encode json err")
		}
	}
}

func main() {

	//Get arguments
	targs, succ := pucommon.NewTaskArgs(os.Args[1:])
	if !succ {
		return
	}

	//Open up the url file
	infile, err := os.Open(BASEDIR + targs.TaskFileName)
	if err != nil {
		panic("Open file fail!")
	}

	taskNum := targs.MapTaskNum
	wg := new(sync.WaitGroup)
	taskChSlice := make([]chan string, 0, taskNum)
	for i := 0; i < taskNum; i++ {
		taskCh := make(chan string)
		taskChSlice = append(taskChSlice, taskCh)
		go mapF(i, taskCh, wg)
	}
	br := bufio.NewReader(infile)
	//send every map task a line(url) which was selected by hash
	for {
		line, _, err := br.ReadLine()
		if err != nil {
			if err != io.EOF {
				panic("reading error!")
			}
			//finish reading, close all map task
			for _, ch := range taskChSlice {
				close(ch)
			}
			break
		}
		strLine := string(line)
		taskNo := pucommon.Ihash(strLine) % len(taskChSlice)
		taskChSlice[taskNo] <- strLine
	}
	infile.Close()
	wg.Wait()

	//reduce task : count every url, write down the result into file and
	// get topn by heap rank
	topheap := heapsort.NewHeap(targs.TopN, false)
	statusfile, serr := os.Create(pucommon.MergeFileName(BASEDIR, REDUCEPHASE, 0))
	if serr != nil {
		panic("create statusfile fail")
	}
	defer statusfile.Close()
	for i := 0; i < taskNum; i++ {
		reduceF(i, topheap, statusfile)
	}
	pucommon.PULOG(topheap.HeapSlice)
	topNF(topheap)
}
